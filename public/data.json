{
  "lastUpdated": "2026-02-19",
  "agents": [
    {
      "rank": 1,
      "name": "Claude Opus 4.6",
      "category": "reasoning",
      "type": "closed",
      "privacy": "high",
      "score": 100,
      "benchmarkScore": 92,
      "link": "https://claude.ai",
      "description": "The best overall. Agentic coding, 1M token context, adaptive thinking.",
      "benchmarks": { "mmlu": 89, "humaneval": 92, "gsm8k": 96.4, "swebench": 72 }
    },
    {
      "rank": 2,
      "name": "GPT-4.5",
      "category": "reasoning",
      "type": "closed",
      "privacy": "medium",
      "score": 98,
      "benchmarkScore": 88,
      "link": "https://openai.com",
      "description": "Latest GPT-4 iteration. Strong across all benchmarks.",
      "benchmarks": { "mmlu": 88.7, "humaneval": 90, "gsm8k": 92, "gpqa": 68 }
    },
    {
      "rank": 3,
      "name": "Gemini 2.5 Pro",
      "category": "research",
      "type": "closed",
      "privacy": "medium",
      "score": 97,
      "benchmarkScore": 87,
      "link": "https://deepmind.google",
      "description": "Best context window (2M tokens). Excellent multimodal.",
      "benchmarks": { "mmlu": 88, "mmmu": 79.6, "gpqa": 65, "humaneval": 88 }
    },
    {
      "rank": 4,
      "name": "MiniMax 2.5",
      "category": "reasoning",
      "type": "closed",
      "privacy": "high",
      "score": 96,
      "benchmarkScore": 89.7,
      "link": "https://minimax.io",
      "description": "Surprise contender. Matches Claude on MMLU. Great pricing.",
      "benchmarks": { "mmlu": 89.7, "gpqa": 65, "humaneval": 87, "gsm8k": 90 }
    },
    {
      "rank": 5,
      "name": "Claude Sonnet 4",
      "category": "reasoning",
      "type": "closed",
      "privacy": "high",
      "score": 95,
      "benchmarkScore": 86,
      "link": "https://claude.ai",
      "description": "Best value Claude. Great for everyday use.",
      "benchmarks": { "mmlu": 88, "humaneval": 92, "gsm8k": 95, "swebench": 72 }
    },
    {
      "rank": 6,
      "name": "o1-pro",
      "category": "reasoning",
      "type": "closed",
      "privacy": "medium",
      "score": 94,
      "benchmarkScore": 91,
      "link": "https://openai.com",
      "description": "Most powerful reasoning. Slow but unmatched on math/code.",
      "benchmarks": { "mmlu": 94, "math": 90, "gpqa": 80, "aime": 87 }
    },
    {
      "rank": 7,
      "name": "DeepSeek V3",
      "category": "reasoning",
      "type": "open-source",
      "privacy": "high",
      "score": 92,
      "benchmarkScore": 84,
      "link": "https://github.com/deepseek-ai",
      "description": "Best open-source overall. Incredible value.",
      "benchmarks": { "mmlu": 87.5, "humaneval": 85, "gsm8k": 88, "math": 70 }
    },
    {
      "rank": 8,
      "name": "Gemini 2.0 Flash",
      "category": "reasoning",
      "type": "closed",
      "privacy": "medium",
      "score": 90,
      "benchmarkScore": 82,
      "link": "https://deepmind.google",
      "description": "Best speed/quality balance. Very fast.",
      "benchmarks": { "mmlu": 85, "humaneval": 84, "gsm8k": 86, "mmmu": 75 }
    },
    {
      "rank": 9,
      "name": "Llama 4 Scout",
      "category": "reasoning",
      "type": "open-source",
      "privacy": "high",
      "score": 88,
      "benchmarkScore": 80,
      "link": "https://llama.meta.com",
      "description": "Meta's best. 10M context window. Great for long docs.",
      "benchmarks": { "mmlu": 86, "humaneval": 82, "gsm8k": 85, "arenaElo": 1280 }
    },
    {
      "rank": 10,
      "name": "Qwen 2.5 Ultra",
      "category": "math",
      "type": "open-source",
      "privacy": "high",
      "score": 87,
      "benchmarkScore": 79,
      "link": "https://github.com/QwenLM",
      "description": "Best open-source for math. Alibaba delivers.",
      "benchmarks": { "mmlu": 86, "math": 75, "gsm8k": 90, "aime": 72 }
    },
    {
      "rank": 11,
      "name": "Mistral Large 2",
      "category": "math",
      "type": "open-source",
      "privacy": "high",
      "score": 85,
      "benchmarkScore": 77,
      "link": "https://mistral.ai",
      "description": "Strong open-source math. Good alternative to Qwen.",
      "benchmarks": { "mmlu": 85, "gsm8k": 92, "math": 68, "aime": 65 }
    },
    {
      "rank": 12,
      "name": "Sonnet 4 (Older)",
      "category": "research",
      "type": "closed",
      "privacy": "high",
      "score": 84,
      "benchmarkScore": 75,
      "link": "https://claude.ai",
      "description": "Still solid. Good for research tasks.",
      "benchmarks": { "mmlu": 86, "gpqa": 55, "humaneval": 88, "mmmu": 68 }
    },
    {
      "rank": 13,
      "name": "Llama 3.3 70B",
      "category": "reasoning",
      "type": "open-source",
      "privacy": "high",
      "score": 82,
      "benchmarkScore": 74,
      "link": "https://llama.meta.com",
      "description": "Reliable open-source. Good for self-hosting.",
      "benchmarks": { "mmlu": 86, "gpqa": 52, "arenaElo": 1250, "humaneval": 80 }
    },
    {
      "rank": 14,
      "name": "Command R7B",
      "category": "reasoning",
      "type": "open-source",
      "privacy": "high",
      "score": 80,
      "benchmarkScore": 72,
      "link": "https://cohere.com",
      "description": "Cohere's best. Good for enterprise use cases.",
      "benchmarks": { "mmlu": 84, "humaneval": 78, "gsm8k": 82, "gpqa": 48 }
    },
    {
      "rank": 15,
      "name": "Yi-Large",
      "category": "learning",
      "type": "open-source",
      "privacy": "high",
      "score": 78,
      "benchmarkScore": 70,
      "link": "https://github.com/01-ai",
      "description": "01.AI's flagship. Competitive with Llama.",
      "benchmarks": { "mmlu": 83, "gpqa": 45, "humaneval": 76, "gsm8k": 80 }
    }
  ]
}
